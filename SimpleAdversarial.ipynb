{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-major",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from scipy.ndimage import maximum_filter\n",
    "import scipy.io as sio\n",
    "import librosa\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-transition",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 44100\n",
    "x_carrier, sr = librosa.load(\"barry.mp3\", sr=sr)\n",
    "x_signal, sr = librosa.load(\"chocolaterain.mp3\", sr=sr)\n",
    "x_signal = x_signal[-sr*20::]\n",
    "x_carrier = x_carrier[-sr*20::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54be126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windowed_softmax(X, time_win, freq_win, temperature=20):\n",
    "    \"\"\"\n",
    "    Compute softmax in a window around each element in a tensor, \n",
    "    using summed area tables to avoid loops\n",
    "    https://en.wikipedia.org/wiki/Summed-area_table\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: torch.tensor(M, N)\n",
    "        2D tensor on which to compute the windowed softmax\n",
    "    time_win: int\n",
    "        Half-width of window\n",
    "    freq_win: int\n",
    "        Half-height of window\n",
    "    temperature: float\n",
    "        Put data into the range [0, temperature] before taking the softmax\n",
    "    \"\"\"\n",
    "    E = torch.exp(temperature*X/torch.max(X))\n",
    "    C = torch.nn.functional.pad(E, (time_win+1, time_win, freq_win+1, freq_win))\n",
    "    C = torch.cumsum(C, axis=1)\n",
    "    C = torch.cumsum(C, axis=0)\n",
    "\n",
    "    fw = freq_win*2+1\n",
    "    tw = time_win*2+1\n",
    "\n",
    "    IA = C[0:-fw, 0:-tw]\n",
    "    IB = C[0:-fw, tw::]\n",
    "    IC = C[fw::, 0:-tw]\n",
    "    ID = C[fw::, tw::]\n",
    "\n",
    "    denom = ID + IA - IB - IC\n",
    "    return E/denom\n",
    "    \n",
    "def make_beepy_tune(S, win, hop, thresh, min_freq=0):\n",
    "    \"\"\"\n",
    "    Make a beepy tune out of the softmax values\n",
    "    \n",
    "    S: ndarray(M, N)\n",
    "        Softmax of spectrogram\n",
    "    win: int\n",
    "        Window length used in spectrogram\n",
    "    hop: int\n",
    "        Hop length used in spectrogram\n",
    "    thresh: float\n",
    "        Threshold above which to include tones\n",
    "    min_freq: float\n",
    "        Frequency below which to ignore peaks\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    x, y = np.meshgrid(np.arange(S.shape[1]), np.arange(S.shape[0]))\n",
    "    hann = 0.5*(1-np.cos(np.linspace(0, 2*np.pi, win)))\n",
    "    yout = np.zeros(S.shape[1]*hop+win)\n",
    "    t = np.arange(win)/sr\n",
    "    for time, freq, mag in zip(x[S > thresh], y[S > thresh], S[S > thresh]):\n",
    "        freq = freq*sr/win\n",
    "        if freq > min_freq and np.isfinite(mag) and yout[time*hop:time*hop+win].size == win:\n",
    "            yout[time*hop:time*hop+win] += mag*hann*np.cos(2*np.pi*freq*t)\n",
    "    return yout\n",
    "\n",
    "\n",
    "\n",
    "## Parameters\n",
    "win = 2048\n",
    "hop = 1024\n",
    "time_win = 3\n",
    "freq_win = 5\n",
    "max_freq = 256\n",
    "temperature = 10\n",
    "thresh = 0.05 # Softmax threshold above which to clamp to 1\n",
    "lam = 0.5 # Weight of maxes term in the loss\n",
    "lam_mask = 30 # Max loss of mask term\n",
    "\n",
    "\n",
    "hann = torch.hann_window(win)\n",
    "XSignal = torch.stft(torch.from_numpy(x_signal), win, hop, win, hann, return_complex=True)\n",
    "XSignal = torch.abs(XSignal)\n",
    "SSignal = get_windowed_softmax(XSignal[0:max_freq+freq_win, :], time_win, freq_win, temperature)[0:max_freq, :]\n",
    "\n",
    "XCarrier = torch.stft(torch.from_numpy(x_carrier), win, hop, win, hann, return_complex=True)\n",
    "XCarrier = torch.abs(XCarrier)\n",
    "SCarrier = get_windowed_softmax(XCarrier[0:max_freq+freq_win, :], time_win, freq_win, temperature)[0:max_freq, :]\n",
    "\n",
    "print(torch.sum(torch.isinf(SSignal)), torch.max(SSignal))\n",
    "print(torch.mean(SSignal[SSignal > thresh]))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(SSignal[0:max_freq, :], aspect='auto', cmap='magma', interpolation='none')\n",
    "plt.ylim([0, max_freq])\n",
    "plt.colorbar()\n",
    "\n",
    "ipd.Audio(make_beepy_tune(SSignal[0:max_freq, :].numpy(), win, hop, thresh), rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e719f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spectral fit loss\n",
    "HANN_TABLE = {}\n",
    "def mss_loss(x, y, eps=1e-7):\n",
    "    loss = 0\n",
    "    win = 64\n",
    "    while win <= 2048:\n",
    "        hop = win//4\n",
    "        if not win in HANN_TABLE:\n",
    "            HANN_TABLE[win] = torch.hann_window(win).to(x)\n",
    "        hann = HANN_TABLE[win]\n",
    "        SX = torch.abs(torch.stft(x, win, hop, win, hann, return_complex=True))\n",
    "        SY = torch.abs(torch.stft(y, win, hop, win, hann, return_complex=True))\n",
    "        loss_win = torch.sum(torch.abs(SX-SY)) + torch.sum(torch.abs(torch.log(SX+eps)-torch.log(SY+eps)))\n",
    "        loss += loss_win/torch.numel(SX)\n",
    "        win *= 2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc077cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "x_orig = torch.from_numpy(x_carrier).to(device)\n",
    "# x = torch.autograd.Variable(torch.atanh(torch.from_numpy(x_carrier)), requires_grad=True).to(device)\n",
    "#x = nn.Parameter(torch.atanh(torch.from_numpy(x_carrier))).to(device)\n",
    "x = torch.from_numpy(x_carrier).to(device)\n",
    "x = torch.atanh(x)\n",
    "x = x.requires_grad_()\n",
    "hann = torch.hann_window(win).to(x)\n",
    "\n",
    "## Step 1: Compute maxes to hide\n",
    "S = torch.abs(torch.stft(torch.from_numpy(x_signal).to(x), win, hop, win, hann, return_complex=True))\n",
    "SMaxSignal = get_windowed_softmax(S[0:max_freq+freq_win, :], time_win, freq_win, temperature)[0:max_freq, :]\n",
    "\n",
    "# Clamp all of the targetmaxes to the 99%th highest max above the threshold\n",
    "# This makes them sound less like the hidden signal\n",
    "q = torch.quantile(SMaxSignal[SMaxSignal > thresh], 0.99)\n",
    "print(\"q\", q)\n",
    "SMaxSignal[SMaxSignal > thresh] = q\n",
    "SMaxSignal[SMaxSignal < thresh] = 0\n",
    "\n",
    "# Create a mask to choose which maxes to include\n",
    "n_mask = torch.sum(SMaxSignal > thresh)\n",
    "mask = 5*torch.ones(n_mask).to(device)\n",
    "mask = mask.requires_grad_()\n",
    "\n",
    "## Step 2: Perform optimization\n",
    "optimizer = torch.optim.Adam([x, mask], lr=1e-2)\n",
    "n_iters = 2000\n",
    "mss_losses = []\n",
    "max_losses = []\n",
    "mask_sums = []\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i in range(n_iters):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    xtan = torch.tanh(x)\n",
    "    loss1 = mss_loss(xtan, x_orig)\n",
    "    mss_losses.append(loss1.item())\n",
    "    \n",
    "    S = torch.abs(torch.stft(xtan, win, hop, win, hann, return_complex=True))\n",
    "    S = get_windowed_softmax(S[0:max_freq+freq_win, :], time_win, freq_win, temperature)[0:max_freq, :]\n",
    "    diff = (S-SMaxSignal)**2\n",
    "    diff[SMaxSignal>thresh] *= torch.sigmoid(mask)*diff[SMaxSignal>thresh]\n",
    "    loss2 = lam*torch.sum(diff)\n",
    "    max_losses.append(loss2.item())\n",
    "    \n",
    "    mask_sum = torch.sum(torch.sigmoid(mask))\n",
    "    mask_sums.append(mask_sum.item())\n",
    "    \n",
    "    loss = loss1 + loss2 - mask_sum*lam_mask/n_mask\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    ## Plot progress every 100 iterations\n",
    "    if i%100 == 0 or i == n_iters-1:  \n",
    "        print(mss_losses[-1], max_losses[-1], mask_sums[-1])\n",
    "        res = torch.tanh(x).detach().cpu().numpy()\n",
    "        \n",
    "        #X = torch.stft(torch.from_numpy(x_signal), win, hop, return_complex=True)\n",
    "        #X = torch.abs(X)\n",
    "        #MHide = maximum_filter(X, (freq_win*2+1, time_win*2+1))\n",
    "        #MHide = (X.numpy() == MHide)*1.0\n",
    "        #MHide = MHide[0:max_freq, :]\n",
    "        MHide = (SMaxSignal.detach().cpu().numpy() == torch.max(SMaxSignal).detach().cpu().numpy())\n",
    "        MHide = MHide[0:max_freq, :]*1.0\n",
    "        \n",
    "        X = torch.stft(torch.from_numpy(res), win, hop, return_complex=True)\n",
    "        X = torch.abs(X)\n",
    "        MCarry = maximum_filter(X, (freq_win*2+1, time_win*2+1))\n",
    "        MCarry = (X.numpy() == MCarry)*1.0\n",
    "        MCarry = MCarry[0:max_freq, :]\n",
    "        \n",
    "        agreed = int(np.sum(MHide*MCarry))\n",
    "        # Maxes that are supposed to be hidden but that are not\n",
    "        false_neg = np.sum((MHide==1)*(MCarry==0))\n",
    "        # Maxes that are not supposed to be hidden but that exist anyway\n",
    "        false_pos = np.sum((MHide==0)*(MCarry==1))\n",
    "        \n",
    "        plt.clf()\n",
    "        \n",
    "        plt.subplot2grid((2, 3), (0, 0), colspan=3)\n",
    "        plt.imshow(MHide-MCarry, cmap='RdBu')\n",
    "        #cbar = plt.colorbar(ticks=[-1, 1])\n",
    "        #cbar.ax.set_yticklabels(['FP', 'FN'])\n",
    "        plt.ylim([0, max_freq])\n",
    "        plt.title(\"{} Agreed, {} False Neg (Blue), {} False Pos (Red), {:.3f} Max Loss\".format(agreed, false_neg, false_pos, max_losses[-1]))\n",
    "        \n",
    "        \n",
    "        plt.subplot(234)\n",
    "        plt.plot(mss_losses)\n",
    "        plt.title(\"MSS Losses {:.3f}\".format(mss_losses[-1]))\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        \n",
    "        plt.subplot(235)\n",
    "        plt.plot(max_losses)\n",
    "        plt.title(\"Max Losses {:.3f}\".format(max_losses[-1]))\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        \n",
    "        plt.subplot(236)\n",
    "        plt.plot(mask_sums)\n",
    "        plt.plot(np.ones(len(mask_sums))*torch.numel(mask))\n",
    "        plt.title(\"Mask Sum {:.3f}\".format(mask_sums[-1]))\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        \n",
    "        plt.savefig(\"%i.png\"%i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a76c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.tanh(x).detach().cpu().numpy()\n",
    "ipd.Audio(res, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0000d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
